{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "after_exam_seven_class.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPv1++uWa2hupmstnbjcBPm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sujangyawali/Fraud_Detection/blob/master/after_exam_seven_class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9afWmdho99l"
      },
      "source": [
        "import warnings\r\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWkbD7QIpLms",
        "outputId": "b6df5efa-2827-4c5a-dd5d-546dfe19db7f"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1doY-2NYpaCL",
        "outputId": "bca4660b-28b5-4a0e-8a11-ed867ded7eef"
      },
      "source": [
        "!pip install keras==2.1.0 \r\n",
        "!pip install tensorflow==1.15.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras==2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bf/c2/b0c2ece713e754d1692aa432ad682751cd1ad6abf7500a534558b1fbfbe7/Keras-2.1.0-py2.py3-none-any.whl (302kB)\n",
            "\r\u001b[K     |█                               | 10kB 24.6MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20kB 31.8MB/s eta 0:00:01\r\u001b[K     |███▎                            | 30kB 23.6MB/s eta 0:00:01\r\u001b[K     |████▍                           | 40kB 21.5MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 51kB 22.6MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 61kB 16.3MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 71kB 16.4MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 81kB 15.9MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 92kB 15.9MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 102kB 16.4MB/s eta 0:00:01\r\u001b[K     |████████████                    | 112kB 16.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 122kB 16.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 133kB 16.4MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 143kB 16.4MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 153kB 16.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 163kB 16.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 174kB 16.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 184kB 16.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 194kB 16.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 204kB 16.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 215kB 16.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 225kB 16.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 235kB 16.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 245kB 16.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 256kB 16.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 266kB 16.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 276kB 16.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 286kB 16.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 296kB 16.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 307kB 16.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.0) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.0) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.1.0) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.0) (1.15.0)\n",
            "\u001b[31mERROR: textgenrnn 1.4.1 has requirement keras>=2.1.5, but you'll have keras 2.1.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "Successfully installed keras-2.1.0\n",
            "Collecting tensorflow==1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 37kB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.32.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 51.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.12.1)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.12.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.3.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 9.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.8.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.2.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.36.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.10.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.19.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.2)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 52.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.3.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (53.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.7.4.3)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=ebb77118fb308b0594634043fa9bbf8e1af9547f3610b477d9f81c78c3580656\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, gast, keras-applications, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaepwPLFplY8"
      },
      "source": [
        "import os \r\n",
        "import sys\r\n",
        "import random\r\n",
        "import math\r\n",
        "import numpy as np\r\n",
        "import cv2\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import json\r\n",
        "from imgaug import augmenters as iaa\r\n",
        "from tqdm import tqdm\r\n",
        "import pandas as pd \r\n",
        "import glob\r\n",
        "from sklearn.model_selection import KFold\r\n",
        "from imgaug import augmenters as iaa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8XXANWxpnqP",
        "outputId": "7f200cc0-7705-4750-b6be-7ba75cc50cea"
      },
      "source": [
        "!git clone https://github.com/matterport/Mask_RCNN.git\r\n",
        "os.chdir('Mask_RCNN')\r\n",
        "!python setup.py install\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Mask_RCNN'...\n",
            "remote: Enumerating objects: 956, done.\u001b[K\n",
            "remote: Total 956 (delta 0), reused 0 (delta 0), pack-reused 956\u001b[K\n",
            "Receiving objects: 100% (956/956), 125.23 MiB | 38.66 MiB/s, done.\n",
            "Resolving deltas: 100% (561/561), done.\n",
            "WARNING:root:Fail load requirements file, so using default ones.\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating mask_rcnn.egg-info\n",
            "writing mask_rcnn.egg-info/PKG-INFO\n",
            "writing dependency_links to mask_rcnn.egg-info/dependency_links.txt\n",
            "writing top-level names to mask_rcnn.egg-info/top_level.txt\n",
            "writing manifest file 'mask_rcnn.egg-info/SOURCES.txt'\n",
            "reading manifest template 'MANIFEST.in'\n",
            "writing manifest file 'mask_rcnn.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/mrcnn\n",
            "copying mrcnn/__init__.py -> build/lib/mrcnn\n",
            "copying mrcnn/parallel_model.py -> build/lib/mrcnn\n",
            "copying mrcnn/config.py -> build/lib/mrcnn\n",
            "copying mrcnn/model.py -> build/lib/mrcnn\n",
            "copying mrcnn/utils.py -> build/lib/mrcnn\n",
            "copying mrcnn/visualize.py -> build/lib/mrcnn\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/__init__.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/parallel_model.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/config.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/model.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/utils.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/visualize.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/parallel_model.py to parallel_model.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/config.py to config.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/model.py to model.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/utils.py to utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/visualize.py to visualize.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating dist\n",
            "creating 'dist/mask_rcnn-2.1-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing mask_rcnn-2.1-py3.6.egg\n",
            "Copying mask_rcnn-2.1-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding mask-rcnn 2.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/mask_rcnn-2.1-py3.6.egg\n",
            "Processing dependencies for mask-rcnn==2.1\n",
            "Finished processing dependencies for mask-rcnn==2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjOcKvxrpnlB",
        "outputId": "6b628901-5344-4e8f-d9d9-7c6a5e9b1cf4"
      },
      "source": [
        "#part of localization\r\n",
        "# example of inference with a pre-trained coco model\r\n",
        "from keras.preprocessing.image import load_img\r\n",
        "from keras.preprocessing.image import img_to_array\r\n",
        "from mrcnn.config import Config\r\n",
        "from mrcnn.model import MaskRCNN\r\n",
        "from matplotlib import pyplot\r\n",
        "from matplotlib.patches import Rectangle\r\n",
        "from mrcnn.utils import Dataset\r\n",
        "from mrcnn.utils import extract_bboxes\r\n",
        "from mrcnn.visualize import display_instances\r\n",
        "from mrcnn.model import MaskRCNN"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7Ygz_-2pnen",
        "outputId": "d226c0a5-8d9a-44c0-f680-c5cec9fcb8bb"
      },
      "source": [
        "# split into train and test set\r\n",
        "from os import listdir\r\n",
        "from xml.etree import ElementTree\r\n",
        "from numpy import zeros\r\n",
        "from numpy import asarray\r\n",
        "from mrcnn.utils import Dataset\r\n",
        "\r\n",
        "class KangarooDataset(Dataset):\r\n",
        "  def load_dataset(self,dataset_dir,is_train=True):\r\n",
        "    self.add_class(\"dataset\",1,\"firetruck\")\r\n",
        "    self.add_class(\"dataset\",2,\"ambulance\")\r\n",
        "    self.add_class(\"dataset\",3,\"hiace\")\r\n",
        "    self.add_class(\"dataset\",4,\"bus\")\r\n",
        "    self.add_class(\"dataset\",5,\"truck\")\r\n",
        "    self.add_class(\"dataset\",6,\"car\")\r\n",
        "    self.add_class(\"dataset\",7,\"jeep\")\r\n",
        "\r\n",
        "    images_dir=dataset_dir + '/images/'\r\n",
        "    annotations_dir=dataset_dir +'/annotation/'\r\n",
        "\r\n",
        "    a=0\r\n",
        "    for filename in listdir(images_dir):\r\n",
        "      a=a+1\r\n",
        "      image_id=filename[:-4]\r\n",
        "\r\n",
        "      if is_train and a <28:\r\n",
        "        continue\r\n",
        "      if not is_train and a>28:\r\n",
        "        continue\r\n",
        "      img_path=images_dir + filename\r\n",
        "      ann_path=annotations_dir+image_id+'.xml'\r\n",
        "\r\n",
        "      self.add_image('dataset',image_id=image_id,path=img_path,annotation=ann_path)\r\n",
        "\r\n",
        "  def extract_boxes(self, filename):\r\n",
        "    # load and parse the file\r\n",
        "    tree = ElementTree.parse(filename)\r\n",
        "    # get the root of the document\r\n",
        "    root = tree.getroot()\r\n",
        "    # extract each object\r\n",
        "    boxes = list()\r\n",
        "    for object in root.findall('.//object'):\r\n",
        "        box_class_list = list()\r\n",
        "        #find bbox coordinates\r\n",
        "        for box in object.findall('.//bndbox'):\r\n",
        "            xmin = int(box.find('xmin').text)\r\n",
        "            ymin = int(box.find('ymin').text)\r\n",
        "            xmax = int(box.find('xmax').text)\r\n",
        "            ymax = int(box.find('ymax').text)\r\n",
        "            coors = [xmin, ymin, xmax, ymax]\r\n",
        "            box_class_list.append(coors)\r\n",
        "        #get the name of the object class corresponding to the bbox\r\n",
        "        for name in object.findall('.//name'):\r\n",
        "            box_class_list.append(name.text)\r\n",
        "        #append the box coors and respective name to a list\r\n",
        "        boxes.append(box_class_list)\r\n",
        "    # extract image dimensions\r\n",
        "    width = int(root.find('.//size/width').text)\r\n",
        "    height = int(root.find('.//size/height').text)\r\n",
        "    return boxes, width, height\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "  def load_mask(self, image_id):\r\n",
        "    # get details of image\r\n",
        "    info = self.image_info[image_id]\r\n",
        "    # define box file location, here the annotation dir in project dir\r\n",
        "    path = info['annotation']\r\n",
        "    # load XML\r\n",
        "    boxes, w, h = self.extract_boxes(path)\r\n",
        "    # create one array for all masks, each on a different channel\r\n",
        "    masks = zeros([h, w, len(boxes)], dtype='uint8')\r\n",
        "    # create masks\r\n",
        "    class_ids = list()\r\n",
        "    for i in range(len(boxes)):\r\n",
        "        box = boxes[i][0]\r\n",
        "        row_s, row_e = box[1], box[3]\r\n",
        "        col_s, col_e = box[0], box[2]\r\n",
        "        masks[row_s:row_e, col_s:col_e, i] = 1\r\n",
        "        class_ids.append(self.class_names.index(boxes[i][1]))\r\n",
        "\r\n",
        "    return masks, asarray(class_ids, dtype='int32') \r\n",
        "\r\n",
        "\r\n",
        "    def image_reference(self,image_id):\r\n",
        "      info=self.image_info[image_id]\r\n",
        "      return info['path']\r\n",
        "\r\n",
        "\r\n",
        "# train set\r\n",
        "train_set = KangarooDataset()\r\n",
        "train_set.load_dataset('/content/drive/MyDrive/for_seven_class', is_train=True)\r\n",
        "train_set.prepare()\r\n",
        "print('Train: %d' % len(train_set.image_ids))\r\n",
        "\r\n",
        "\r\n",
        "# test/val set\r\n",
        "test_set = KangarooDataset()\r\n",
        "test_set.load_dataset('/content/drive/MyDrive/for_seven_class', is_train=False)\r\n",
        "test_set.prepare()\r\n",
        "print('Test: %d' % len(test_set.image_ids))\r\n",
        "        "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: 199\n",
            "Test: 28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KG6D9q3FpnbV",
        "outputId": "2cad6862-d5b6-411c-a784-360edef4ec32"
      },
      "source": [
        "from mrcnn.config import Config\r\n",
        "# define a configuration for the model\r\n",
        "class FiretruckConfig(Config):\r\n",
        "\t# Give the configuration a recognizable name\r\n",
        "\tNAME = \"sevenclass_cfg\"\r\n",
        "\t# Number of classes (background + kangaroo)\r\n",
        "\tNUM_CLASSES = 1 + 7\r\n",
        "\tGPU_COUNT=1\r\n",
        "\t# Number of training steps per epoch\r\n",
        "\tSTEPS_PER_EPOCH=110\r\n",
        "\r\n",
        "# prepare config\r\n",
        "config = FiretruckConfig()\r\n",
        "config.display()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Configurations:\n",
            "BACKBONE                       resnet101\n",
            "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
            "BATCH_SIZE                     2\n",
            "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
            "COMPUTE_BACKBONE_SHAPE         None\n",
            "DETECTION_MAX_INSTANCES        100\n",
            "DETECTION_MIN_CONFIDENCE       0.7\n",
            "DETECTION_NMS_THRESHOLD        0.3\n",
            "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
            "GPU_COUNT                      1\n",
            "GRADIENT_CLIP_NORM             5.0\n",
            "IMAGES_PER_GPU                 2\n",
            "IMAGE_CHANNEL_COUNT            3\n",
            "IMAGE_MAX_DIM                  1024\n",
            "IMAGE_META_SIZE                20\n",
            "IMAGE_MIN_DIM                  800\n",
            "IMAGE_MIN_SCALE                0\n",
            "IMAGE_RESIZE_MODE              square\n",
            "IMAGE_SHAPE                    [1024 1024    3]\n",
            "LEARNING_MOMENTUM              0.9\n",
            "LEARNING_RATE                  0.001\n",
            "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
            "MASK_POOL_SIZE                 14\n",
            "MASK_SHAPE                     [28, 28]\n",
            "MAX_GT_INSTANCES               100\n",
            "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
            "MINI_MASK_SHAPE                (56, 56)\n",
            "NAME                           sevenclass_cfg\n",
            "NUM_CLASSES                    8\n",
            "POOL_SIZE                      7\n",
            "POST_NMS_ROIS_INFERENCE        1000\n",
            "POST_NMS_ROIS_TRAINING         2000\n",
            "PRE_NMS_LIMIT                  6000\n",
            "ROI_POSITIVE_RATIO             0.33\n",
            "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
            "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
            "RPN_ANCHOR_STRIDE              1\n",
            "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
            "RPN_NMS_THRESHOLD              0.7\n",
            "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
            "STEPS_PER_EPOCH                110\n",
            "TOP_DOWN_PYRAMID_SIZE          256\n",
            "TRAIN_BN                       False\n",
            "TRAIN_ROIS_PER_IMAGE           200\n",
            "USE_MINI_MASK                  True\n",
            "USE_RPN_ROIS                   True\n",
            "VALIDATION_STEPS               50\n",
            "WEIGHT_DECAY                   0.0001\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NArrW1TvpnZF",
        "outputId": "77d0c097-af07-4ffe-a56c-bb2545981980"
      },
      "source": [
        "import mrcnn.model as modellib\r\n",
        "# define the model\r\n",
        "model = modellib.MaskRCNN(mode='training', model_dir='./', config=config)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:492: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:63: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3630: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3458: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1822: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1208: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1242: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:553: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/utils.py:202: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:600: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3k9qDJKpnVs"
      },
      "source": [
        "!wget --quiet https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5\r\n",
        "    #downloading weight into the current directory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IR3z5-sMpnR7",
        "outputId": "05b7ebf2-79eb-4040-b6cc-f4cbb5baf28b"
      },
      "source": [
        "# load weights (mscoco)\r\n",
        "model.load_weights('/content/Mask_RCNN/mask_rcnn_coco.h5', by_name=True,\r\n",
        "                   exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:158: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:163: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:168: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:172: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:188: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sy6D2DRJpnOT",
        "outputId": "9ac30bc4-31f7-4233-b498-024a2200cda8"
      },
      "source": [
        "# train weights (output layers or 'heads')\r\n",
        "history=model.train(train_set, test_set, learning_rate=config.LEARNING_RATE, epochs=20, layers='all')\r\n",
        "new_history = model.keras_model.history.history"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Starting at epoch 0. LR=0.001\n",
            "\n",
            "Checkpoint Path: ./sevenclass_cfg20210206T1908/mask_rcnn_sevenclass_cfg_{epoch:04d}.h5\n",
            "Selecting layers to train\n",
            "conv1                  (Conv2D)\n",
            "bn_conv1               (BatchNorm)\n",
            "res2a_branch2a         (Conv2D)\n",
            "bn2a_branch2a          (BatchNorm)\n",
            "res2a_branch2b         (Conv2D)\n",
            "bn2a_branch2b          (BatchNorm)\n",
            "res2a_branch2c         (Conv2D)\n",
            "res2a_branch1          (Conv2D)\n",
            "bn2a_branch2c          (BatchNorm)\n",
            "bn2a_branch1           (BatchNorm)\n",
            "res2b_branch2a         (Conv2D)\n",
            "bn2b_branch2a          (BatchNorm)\n",
            "res2b_branch2b         (Conv2D)\n",
            "bn2b_branch2b          (BatchNorm)\n",
            "res2b_branch2c         (Conv2D)\n",
            "bn2b_branch2c          (BatchNorm)\n",
            "res2c_branch2a         (Conv2D)\n",
            "bn2c_branch2a          (BatchNorm)\n",
            "res2c_branch2b         (Conv2D)\n",
            "bn2c_branch2b          (BatchNorm)\n",
            "res2c_branch2c         (Conv2D)\n",
            "bn2c_branch2c          (BatchNorm)\n",
            "res3a_branch2a         (Conv2D)\n",
            "bn3a_branch2a          (BatchNorm)\n",
            "res3a_branch2b         (Conv2D)\n",
            "bn3a_branch2b          (BatchNorm)\n",
            "res3a_branch2c         (Conv2D)\n",
            "res3a_branch1          (Conv2D)\n",
            "bn3a_branch2c          (BatchNorm)\n",
            "bn3a_branch1           (BatchNorm)\n",
            "res3b_branch2a         (Conv2D)\n",
            "bn3b_branch2a          (BatchNorm)\n",
            "res3b_branch2b         (Conv2D)\n",
            "bn3b_branch2b          (BatchNorm)\n",
            "res3b_branch2c         (Conv2D)\n",
            "bn3b_branch2c          (BatchNorm)\n",
            "res3c_branch2a         (Conv2D)\n",
            "bn3c_branch2a          (BatchNorm)\n",
            "res3c_branch2b         (Conv2D)\n",
            "bn3c_branch2b          (BatchNorm)\n",
            "res3c_branch2c         (Conv2D)\n",
            "bn3c_branch2c          (BatchNorm)\n",
            "res3d_branch2a         (Conv2D)\n",
            "bn3d_branch2a          (BatchNorm)\n",
            "res3d_branch2b         (Conv2D)\n",
            "bn3d_branch2b          (BatchNorm)\n",
            "res3d_branch2c         (Conv2D)\n",
            "bn3d_branch2c          (BatchNorm)\n",
            "res4a_branch2a         (Conv2D)\n",
            "bn4a_branch2a          (BatchNorm)\n",
            "res4a_branch2b         (Conv2D)\n",
            "bn4a_branch2b          (BatchNorm)\n",
            "res4a_branch2c         (Conv2D)\n",
            "res4a_branch1          (Conv2D)\n",
            "bn4a_branch2c          (BatchNorm)\n",
            "bn4a_branch1           (BatchNorm)\n",
            "res4b_branch2a         (Conv2D)\n",
            "bn4b_branch2a          (BatchNorm)\n",
            "res4b_branch2b         (Conv2D)\n",
            "bn4b_branch2b          (BatchNorm)\n",
            "res4b_branch2c         (Conv2D)\n",
            "bn4b_branch2c          (BatchNorm)\n",
            "res4c_branch2a         (Conv2D)\n",
            "bn4c_branch2a          (BatchNorm)\n",
            "res4c_branch2b         (Conv2D)\n",
            "bn4c_branch2b          (BatchNorm)\n",
            "res4c_branch2c         (Conv2D)\n",
            "bn4c_branch2c          (BatchNorm)\n",
            "res4d_branch2a         (Conv2D)\n",
            "bn4d_branch2a          (BatchNorm)\n",
            "res4d_branch2b         (Conv2D)\n",
            "bn4d_branch2b          (BatchNorm)\n",
            "res4d_branch2c         (Conv2D)\n",
            "bn4d_branch2c          (BatchNorm)\n",
            "res4e_branch2a         (Conv2D)\n",
            "bn4e_branch2a          (BatchNorm)\n",
            "res4e_branch2b         (Conv2D)\n",
            "bn4e_branch2b          (BatchNorm)\n",
            "res4e_branch2c         (Conv2D)\n",
            "bn4e_branch2c          (BatchNorm)\n",
            "res4f_branch2a         (Conv2D)\n",
            "bn4f_branch2a          (BatchNorm)\n",
            "res4f_branch2b         (Conv2D)\n",
            "bn4f_branch2b          (BatchNorm)\n",
            "res4f_branch2c         (Conv2D)\n",
            "bn4f_branch2c          (BatchNorm)\n",
            "res4g_branch2a         (Conv2D)\n",
            "bn4g_branch2a          (BatchNorm)\n",
            "res4g_branch2b         (Conv2D)\n",
            "bn4g_branch2b          (BatchNorm)\n",
            "res4g_branch2c         (Conv2D)\n",
            "bn4g_branch2c          (BatchNorm)\n",
            "res4h_branch2a         (Conv2D)\n",
            "bn4h_branch2a          (BatchNorm)\n",
            "res4h_branch2b         (Conv2D)\n",
            "bn4h_branch2b          (BatchNorm)\n",
            "res4h_branch2c         (Conv2D)\n",
            "bn4h_branch2c          (BatchNorm)\n",
            "res4i_branch2a         (Conv2D)\n",
            "bn4i_branch2a          (BatchNorm)\n",
            "res4i_branch2b         (Conv2D)\n",
            "bn4i_branch2b          (BatchNorm)\n",
            "res4i_branch2c         (Conv2D)\n",
            "bn4i_branch2c          (BatchNorm)\n",
            "res4j_branch2a         (Conv2D)\n",
            "bn4j_branch2a          (BatchNorm)\n",
            "res4j_branch2b         (Conv2D)\n",
            "bn4j_branch2b          (BatchNorm)\n",
            "res4j_branch2c         (Conv2D)\n",
            "bn4j_branch2c          (BatchNorm)\n",
            "res4k_branch2a         (Conv2D)\n",
            "bn4k_branch2a          (BatchNorm)\n",
            "res4k_branch2b         (Conv2D)\n",
            "bn4k_branch2b          (BatchNorm)\n",
            "res4k_branch2c         (Conv2D)\n",
            "bn4k_branch2c          (BatchNorm)\n",
            "res4l_branch2a         (Conv2D)\n",
            "bn4l_branch2a          (BatchNorm)\n",
            "res4l_branch2b         (Conv2D)\n",
            "bn4l_branch2b          (BatchNorm)\n",
            "res4l_branch2c         (Conv2D)\n",
            "bn4l_branch2c          (BatchNorm)\n",
            "res4m_branch2a         (Conv2D)\n",
            "bn4m_branch2a          (BatchNorm)\n",
            "res4m_branch2b         (Conv2D)\n",
            "bn4m_branch2b          (BatchNorm)\n",
            "res4m_branch2c         (Conv2D)\n",
            "bn4m_branch2c          (BatchNorm)\n",
            "res4n_branch2a         (Conv2D)\n",
            "bn4n_branch2a          (BatchNorm)\n",
            "res4n_branch2b         (Conv2D)\n",
            "bn4n_branch2b          (BatchNorm)\n",
            "res4n_branch2c         (Conv2D)\n",
            "bn4n_branch2c          (BatchNorm)\n",
            "res4o_branch2a         (Conv2D)\n",
            "bn4o_branch2a          (BatchNorm)\n",
            "res4o_branch2b         (Conv2D)\n",
            "bn4o_branch2b          (BatchNorm)\n",
            "res4o_branch2c         (Conv2D)\n",
            "bn4o_branch2c          (BatchNorm)\n",
            "res4p_branch2a         (Conv2D)\n",
            "bn4p_branch2a          (BatchNorm)\n",
            "res4p_branch2b         (Conv2D)\n",
            "bn4p_branch2b          (BatchNorm)\n",
            "res4p_branch2c         (Conv2D)\n",
            "bn4p_branch2c          (BatchNorm)\n",
            "res4q_branch2a         (Conv2D)\n",
            "bn4q_branch2a          (BatchNorm)\n",
            "res4q_branch2b         (Conv2D)\n",
            "bn4q_branch2b          (BatchNorm)\n",
            "res4q_branch2c         (Conv2D)\n",
            "bn4q_branch2c          (BatchNorm)\n",
            "res4r_branch2a         (Conv2D)\n",
            "bn4r_branch2a          (BatchNorm)\n",
            "res4r_branch2b         (Conv2D)\n",
            "bn4r_branch2b          (BatchNorm)\n",
            "res4r_branch2c         (Conv2D)\n",
            "bn4r_branch2c          (BatchNorm)\n",
            "res4s_branch2a         (Conv2D)\n",
            "bn4s_branch2a          (BatchNorm)\n",
            "res4s_branch2b         (Conv2D)\n",
            "bn4s_branch2b          (BatchNorm)\n",
            "res4s_branch2c         (Conv2D)\n",
            "bn4s_branch2c          (BatchNorm)\n",
            "res4t_branch2a         (Conv2D)\n",
            "bn4t_branch2a          (BatchNorm)\n",
            "res4t_branch2b         (Conv2D)\n",
            "bn4t_branch2b          (BatchNorm)\n",
            "res4t_branch2c         (Conv2D)\n",
            "bn4t_branch2c          (BatchNorm)\n",
            "res4u_branch2a         (Conv2D)\n",
            "bn4u_branch2a          (BatchNorm)\n",
            "res4u_branch2b         (Conv2D)\n",
            "bn4u_branch2b          (BatchNorm)\n",
            "res4u_branch2c         (Conv2D)\n",
            "bn4u_branch2c          (BatchNorm)\n",
            "res4v_branch2a         (Conv2D)\n",
            "bn4v_branch2a          (BatchNorm)\n",
            "res4v_branch2b         (Conv2D)\n",
            "bn4v_branch2b          (BatchNorm)\n",
            "res4v_branch2c         (Conv2D)\n",
            "bn4v_branch2c          (BatchNorm)\n",
            "res4w_branch2a         (Conv2D)\n",
            "bn4w_branch2a          (BatchNorm)\n",
            "res4w_branch2b         (Conv2D)\n",
            "bn4w_branch2b          (BatchNorm)\n",
            "res4w_branch2c         (Conv2D)\n",
            "bn4w_branch2c          (BatchNorm)\n",
            "res5a_branch2a         (Conv2D)\n",
            "bn5a_branch2a          (BatchNorm)\n",
            "res5a_branch2b         (Conv2D)\n",
            "bn5a_branch2b          (BatchNorm)\n",
            "res5a_branch2c         (Conv2D)\n",
            "res5a_branch1          (Conv2D)\n",
            "bn5a_branch2c          (BatchNorm)\n",
            "bn5a_branch1           (BatchNorm)\n",
            "res5b_branch2a         (Conv2D)\n",
            "bn5b_branch2a          (BatchNorm)\n",
            "res5b_branch2b         (Conv2D)\n",
            "bn5b_branch2b          (BatchNorm)\n",
            "res5b_branch2c         (Conv2D)\n",
            "bn5b_branch2c          (BatchNorm)\n",
            "res5c_branch2a         (Conv2D)\n",
            "bn5c_branch2a          (BatchNorm)\n",
            "res5c_branch2b         (Conv2D)\n",
            "bn5c_branch2b          (BatchNorm)\n",
            "res5c_branch2c         (Conv2D)\n",
            "bn5c_branch2c          (BatchNorm)\n",
            "fpn_c5p5               (Conv2D)\n",
            "fpn_c4p4               (Conv2D)\n",
            "fpn_c3p3               (Conv2D)\n",
            "fpn_c2p2               (Conv2D)\n",
            "fpn_p5                 (Conv2D)\n",
            "fpn_p2                 (Conv2D)\n",
            "fpn_p3                 (Conv2D)\n",
            "fpn_p4                 (Conv2D)\n",
            "In model:  rpn_model\n",
            "    rpn_conv_shared        (Conv2D)\n",
            "    rpn_class_raw          (Conv2D)\n",
            "    rpn_bbox_pred          (Conv2D)\n",
            "mrcnn_mask_conv1       (TimeDistributed)\n",
            "mrcnn_mask_bn1         (TimeDistributed)\n",
            "mrcnn_mask_conv2       (TimeDistributed)\n",
            "mrcnn_mask_bn2         (TimeDistributed)\n",
            "mrcnn_class_conv1      (TimeDistributed)\n",
            "mrcnn_class_bn1        (TimeDistributed)\n",
            "mrcnn_mask_conv3       (TimeDistributed)\n",
            "mrcnn_mask_bn3         (TimeDistributed)\n",
            "mrcnn_class_conv2      (TimeDistributed)\n",
            "mrcnn_class_bn2        (TimeDistributed)\n",
            "mrcnn_mask_conv4       (TimeDistributed)\n",
            "mrcnn_mask_bn4         (TimeDistributed)\n",
            "mrcnn_bbox_fc          (TimeDistributed)\n",
            "mrcnn_mask_deconv      (TimeDistributed)\n",
            "mrcnn_class_logits     (TimeDistributed)\n",
            "mrcnn_mask             (TimeDistributed)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:711: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:953: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:675: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:940: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:705: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:708: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:root:Error processing image {'id': 'vid26.mp4frame195', 'source': 'dataset', 'path': '/content/drive/MyDrive/for_seven_class/images/vid26.mp4frame195.jpg', 'annotation': '/content/drive/MyDrive/for_seven_class/annotation/vid26.mp4frame195.xml'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/Mask_RCNN/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"<ipython-input-9-d8107bf9b7c4>\", line 70, in load_mask\n",
            "    boxes, w, h = self.extract_boxes(path)\n",
            "  File \"<ipython-input-9-d8107bf9b7c4>\", line 37, in extract_boxes\n",
            "    tree = ElementTree.parse(filename)\n",
            "  File \"/usr/lib/python3.6/xml/etree/ElementTree.py\", line 1196, in parse\n",
            "    tree.parse(source, parser)\n",
            "  File \"/usr/lib/python3.6/xml/etree/ElementTree.py\", line 586, in parse\n",
            "    source = open(source, \"rb\")\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/for_seven_class/annotation/vid26.mp4frame195.xml'\n",
            "ERROR:root:Error processing image {'id': 'vid121.mp4frame210', 'source': 'dataset', 'path': '/content/drive/MyDrive/for_seven_class/images/vid121.mp4frame210.jpg', 'annotation': '/content/drive/MyDrive/for_seven_class/annotation/vid121.mp4frame210.xml'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/Mask_RCNN/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"<ipython-input-9-d8107bf9b7c4>\", line 70, in load_mask\n",
            "    boxes, w, h = self.extract_boxes(path)\n",
            "  File \"<ipython-input-9-d8107bf9b7c4>\", line 37, in extract_boxes\n",
            "    tree = ElementTree.parse(filename)\n",
            "  File \"/usr/lib/python3.6/xml/etree/ElementTree.py\", line 1196, in parse\n",
            "    tree.parse(source, parser)\n",
            "  File \"/usr/lib/python3.6/xml/etree/ElementTree.py\", line 586, in parse\n",
            "    source = open(source, \"rb\")\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/for_seven_class/annotation/vid121.mp4frame210.xml'\n",
            "ERROR:root:Error processing image {'id': 'vid122.mp4frame0', 'source': 'dataset', 'path': '/content/drive/MyDrive/for_seven_class/images/vid122.mp4frame0.jpg', 'annotation': '/content/drive/MyDrive/for_seven_class/annotation/vid122.mp4frame0.xml'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/Mask_RCNN/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"<ipython-input-9-d8107bf9b7c4>\", line 70, in load_mask\n",
            "    boxes, w, h = self.extract_boxes(path)\n",
            "  File \"<ipython-input-9-d8107bf9b7c4>\", line 37, in extract_boxes\n",
            "    tree = ElementTree.parse(filename)\n",
            "  File \"/usr/lib/python3.6/xml/etree/ElementTree.py\", line 1196, in parse\n",
            "    tree.parse(source, parser)\n",
            "  File \"/usr/lib/python3.6/xml/etree/ElementTree.py\", line 586, in parse\n",
            "    source = open(source, \"rb\")\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/for_seven_class/annotation/vid122.mp4frame0.xml'\n",
            "ERROR:root:Error processing image {'id': 'vid122.mp4frame0', 'source': 'dataset', 'path': '/content/drive/MyDrive/for_seven_class/images/vid122.mp4frame0.jpg', 'annotation': '/content/drive/MyDrive/for_seven_class/annotation/vid122.mp4frame0.xml'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/Mask_RCNN/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"<ipython-input-9-d8107bf9b7c4>\", line 70, in load_mask\n",
            "    boxes, w, h = self.extract_boxes(path)\n",
            "  File \"<ipython-input-9-d8107bf9b7c4>\", line 37, in extract_boxes\n",
            "    tree = ElementTree.parse(filename)\n",
            "  File \"/usr/lib/python3.6/xml/etree/ElementTree.py\", line 1196, in parse\n",
            "    tree.parse(source, parser)\n",
            "  File \"/usr/lib/python3.6/xml/etree/ElementTree.py\", line 586, in parse\n",
            "    source = open(source, \"rb\")\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/for_seven_class/annotation/vid122.mp4frame0.xml'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 12/110 [==>...........................] - ETA: 3:56:51 - loss: 2.4451 - rpn_class_loss: 0.0122 - rpn_bbox_loss: 0.3981 - mrcnn_class_loss: 0.5979 - mrcnn_bbox_loss: 0.8146 - mrcnn_mask_loss: 0.6223"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "uOkH-yY4pnLE",
        "outputId": "125cccb8-bc3f-40ea-cef8-f7d2b30a3a23"
      },
      "source": [
        "epochs = range(1, len(new_history['loss'])+1)\r\n",
        "pd.DataFrame(new_history, index=epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-7ef1756aebb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'new_history' is not defined"
          ]
        }
      ]
    }
  ]
}